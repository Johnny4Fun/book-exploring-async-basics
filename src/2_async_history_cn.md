# 异步编程的历史

原文地址：

[Async history](https://cfsamson.github.io/book-exploring-async-basics/2_async_history.html#async-history)

译者注：

- 已经征得原作者同意，翻译文档和把翻译半成品放在知乎上，详见[issue](https://github.com/cfsamson/book-exploring-async-basics/issues/28)。

- 对于文章中不理解、难翻译的部分，我会咨询作者本人，主要[通过issue交流](https://github.com/cfsamson/book-exploring-async-basics/issues/28)，尽量确保翻译最基本的准确性。大家如果对翻译有异议的、对内容有疑问的都可以提出来，自己在github上[提issue](https://github.com/cfsamson/book-exploring-async-basics/issues/)或者我帮你提。
- 考虑到第一章中英文混合的方法看起来有点杂乱，所以目前采用的翻译方式是把中文翻译独立出来，放在`xxxx_cn.md`，方便对照。



最初，计算机只有一个CPU（单核），按顺序一条条地执行程序员的指令。没有任务调度、没有线程、没有多任务的概念。这就是很长一段时间里计算机工作的方式。当年所谓的程序就是像这样的打孔纸带。

![Image](./images/punched_card_deck.jpg)

在计算机发展的早期，就已经有很多人在研究操作系统。当80年代个人计算设备开始兴起时，DOS就是当时大多数消费者PC的标配。

这类操作系统通常会将整个CPU的控制权交给当前正在执行的程序，由程序员来完成工作，并为其程序实现任何类型的多任务处理机制。这很有效，但是随着使用鼠标的交互式UI和窗口化操作系统成为标准，这个模式就不再管用了。

## 非抢占式多任务处理机制

第一种解决方法是通过我们所说的`非抢占式多任务处理机制`来实现的，它能够保持UI的交互（并运行后台进程）。

在这种类型的多任务处理机制下，程序员需要决定何时让操作系统运行其他任务如回应鼠标输入或者运行后台任务。

通常来说，程序员要（定时）将控制权**转交**给操作系统，以便操作系统处理上述任务。

除此之外，每一个在你的平台编写代码的程序员都承担着重大的责任，这自然是容易出错的。程序代码中一个小小的错误可能会引起整个系统的停止或崩溃。

>如果你还记得Windows 95，你应该会记得当一个窗口卡死时，你可以用它画满整个屏幕（就像Windows自带的纸牌游戏的结局一样）。
>
>据悉，这是代码中的一个典型错误，即程序本应将控制权交给操作系统但实际上并没有。

## 抢占式多任务处理机制

虽然非抢占多任务处理机制看起来是个好主意，但是也产生了严重的问题——每个程序与程序员都有控制操作系统UI响应的权限，这可能最终会导致较差的用户体验，因为只要出现一个bug都有可能导致整个系统停止。

解决这个问题的方式就是将在程序中调度CPU资源的职责交给操作系统。操作系统可以暂停进程的执行，执行其他的操作，然后再切换回去。

在一台单核机器上，可以想象，当运行你写的程序时，操作系统必须不时地暂停程序来更新鼠标位置，然后再切换回你的程序继续执行。CPU切换的频率很高，以致我们无法分辨出CPU处于繁忙还是空闲状态。

后来，通过切换CPU的上下文使操作系统负责执行任务调度。切换的流程在每秒可以发生许多次，不仅仅是为了保持UI响应，也可以给其他后台任务和I/O事件分配一定的时间片。

这也是现在设计操作系统的主流方法。

> 如果你想要了解更多关于这类多线程的多任务处理机制，建议你读一读我之前的那被关于[green threads](https://cfsamson.gitbook.io/green-threads-explained-in-200-lines-of-rust/)的书。这是一篇很好的导读书籍，你可以在其中得到你所需要的关于线程、上下文、堆栈和任务调度的基本知识。

## 超线程技术

随着CPU的演进和其越来越多的新增功能 ，比如说若干个算术逻辑单元（ALU）以及额外的逻辑单元，CPU的制造商意识到整颗CPU从没有被完全利用。举个例子，因为一个运算只需要CPU的一部分，所以在同一ALU上可以同时地、并行地执行另一个指令。这就是超线程的开端。

瞧，你的计算机有比如6个核心，12个逻辑核心。这正是超线程技术所带来的效果。这个技术通过使用在线程1执行时CPU的未使用部分来同时执行线程2。实现的方式就是使用一系列聪明的小技巧（就像ALU上的使用的那个一样）。

在超线程技术的加持下，即使我们只有一个单核CPU，事实上我们仍可以将一些工作分配到一个线程上，同时，通过在另一个线程中响应UI事件来保持UI的可交互性，从而更好地利用硬件资源。

> 你可能好奇超线程技术带来的性能上的提升？
>
> 超线程技术自90年代以来一直在持续地改进。然而，实际上两个核心还是模拟出来的，并非真正的双核CPU，所以还是会存在一些操作必须要等待另一个完成才能继续进行。在一颗单核处理器上，超线程所带来得多任务处理性能上的提升[在某种某些方面接近30 %](https://en.wikipedia.org/wiki/Hyper-threading#Performance_claims) ，但主要还是取决于工作负载。

## 多核处理器

众所周知，处理器的时钟频率已经很长时间处于一个发展的平稳期。通过改进缓存、分支预测、预测执行、流水线处理等技术，处理器的速度越来越快，然而这些改进的收效开始逐渐减少。

另一方面，新的处理器的越来越小的体积使得我们能够在同样大小的芯片下集成更多的处理器（核心）。如今，大多数的CPU都有多个核心，而且基本上每个核心都支持超线程。

## 所以你的代码真的是同步的吗？

和大多数事情一样，这取决于你看问题的角度。从你的程序和程序代码角度来看，一切通常都会按照你编写的顺序发生。

从操作系统的角度来看，操作系统可能会/也可能不会中断、暂停你的程序，在恢复运行你的程序之前，运行一些其他的程序。

对于CPU而言，它大多数情况下一次只执行一条指令*。CPU不关心谁写的这个程序，所以当硬件中断发生时，CPU会立即停下，将控制权让给中断处理程序。这就是CPU处理并发的方式。


> *事实上，现代CPU可以并行地执行很多操作。大多数CPU是支持流水线方式的，这就意味着当前的指令在执行的同时，下一条的指令就会被装载进来。CPU也可能拥有一个分支预测器，用于预测接下来需要载入的指令。
>
> 处理器也可以在不通知程序员和操作系统的前提下，通过使用“乱序执行”来重新排列指令顺序，如果它认为这样能加快处理速度的话。所以不能保证A一定发生在B之前。
>
> CPU将一些工作转移到独立的协处理器上，比如用于进行浮点运算的FPU，将主CPU腾出来执行其他任务等。
>
> 在高级层次上看，我们可以认为CPU是以同步的方式运行的，但是需要注意的是，这个观点并不是严格意义上完全正确的，特别是当我们讨论并行机制、同步原语（如互斥操作mutex和原子操作atomic）以及计算机和操作系统安全等底层的内容时。也就是说，从底层的视角来看，CPU实际上是异步的，所以我们才会需要同步原语等机制来保证同步。
